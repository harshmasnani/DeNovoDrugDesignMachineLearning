{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('ACT11_competition_training.csv', dtype={\"MOLECULE\": object, \"Act\": float})\n",
    "\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get truth values and reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6399,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=train['Act'].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6399, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.reshape(y,(-1,1))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop(['Act', 'MOLECULE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Provided by MERCK\n",
    "def r_square(X, Y):\n",
    "    \"\"\" r^2 value defined by the competition host, r^2 = 1 indicates 100% prediction accuracy\n",
    "    \"\"\"\n",
    "    avx = np.mean(X)\n",
    "    avy = np.mean(Y)\n",
    "    sum1, sumx, sumy = 0, 0, 0\n",
    "    for i in range(len(X)):\n",
    "        sum1 += (X[i] - avx)*(Y[i] - avy)\n",
    "        sumx += (X[i] - avx)*(X[i] - avx)\n",
    "        sumy += (Y[i] - avy)*(Y[i] - avy)\n",
    "    print(len(X), sum1, sumx, sumy)\n",
    "    return sum1*sum1/(sumx*sumy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Transformation. Loop five times and retain R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- round 0-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevinyan/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26684064\n",
      "640 [-0.27439375] 0.042271289301424986 [170.07633203]\n",
      "R^2: [0.01047271]\n",
      "-------------------- round 1-----------------------\n",
      "0.2743149\n",
      "640 [-0.2293674] 0.037354285246866015 [173.91947516]\n",
      "R^2: [0.00809794]\n",
      "-------------------- round 2-----------------------\n",
      "0.27306953\n",
      "640 [0.50432041] 0.30647475943071356 [174.42796664]\n",
      "R^2: [0.00475776]\n",
      "-------------------- round 3-----------------------\n",
      "0.29079437\n",
      "640 [4.3063445] 0.897780654532788 [185.22642949]\n",
      "R^2: [0.11151784]\n",
      "-------------------- round 4-----------------------\n",
      "0.27804476\n",
      "640 [0.85099426] 0.06687522772817811 [176.41169298]\n",
      "R^2: [0.06138477]\n",
      "-------------------- round 5-----------------------\n",
      "0.27180532\n",
      "640 [2.22712937] 0.2327537966190496 [177.38242231]\n",
      "R^2: [0.12013887]\n",
      "-------------------- round 6-----------------------\n",
      "0.26793662\n",
      "640 [3.31963257] 1.0090597402603265 [176.84512422]\n",
      "R^2: [0.06175471]\n",
      "-------------------- round 7-----------------------\n",
      "0.28912577\n",
      "640 [0.09014242] 0.008016216358921247 [184.41166136]\n",
      "R^2: [0.00549668]\n",
      "-------------------- round 8-----------------------\n",
      "0.27640072\n",
      "640 [-0.06357582] 0.0060622503845664255 [176.66879296]\n",
      "R^2: [0.0037739]\n",
      "-------------------- round 9-----------------------\n",
      "0.27754265\n",
      "640 [8.90628322] 3.129681674050719 [191.80644924]\n",
      "R^2: [0.13213858]\n"
     ]
    }
   ],
   "source": [
    "for index_1 in range(10):\n",
    "    print(\"-------------------- round \"+str(index_1)+\"-----------------------\")\n",
    "    x=train.values\n",
    "    seed = round(np.random.uniform(1, len(x)))\n",
    "    X_train, X_dev, Y_train, Y_dev = train_test_split(x, y, train_size = 0.80, random_state = seed)\n",
    "    X_val, X_test, Y_val, Y_test = train_test_split(X_dev, Y_dev, train_size = 0.50, random_state = seed)\n",
    "\n",
    "    X_placeholder = tf.placeholder(tf.float32, (None, X_train.shape[1]))\n",
    "    Y_placeholder = tf.placeholder(tf.float32, (None, Y_train.shape[1]))\n",
    "\n",
    "    # define parameters\n",
    "    features = np.shape(X_train)[1]\n",
    "    target_size = np.shape(X_train)[0]\n",
    "\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    epochs = 900\n",
    "    batch_size = 300\n",
    "\n",
    "    batch_size_placeholder = tf.placeholder(tf.int64)\n",
    "\n",
    "    # network parameters\n",
    "    n_hidden_1 = 50\n",
    "    n_hidden_2 = 25\n",
    "\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices(( X_placeholder, Y_placeholder )).shuffle(buffer_size=round(len(X_train) * 0.3)).batch(batch_size_placeholder)\n",
    "\n",
    "    ds_test = tf.data.Dataset.from_tensor_slices(( X_placeholder, Y_placeholder )).batch( batch_size_placeholder )\n",
    "\n",
    "    ds_iter = tf.data.Iterator.from_structure(ds_train.output_types, ds_train.output_shapes)\n",
    "\n",
    "    next_x, next_y = ds_iter.get_next()\n",
    "\n",
    "    train_init_op = ds_iter.make_initializer(ds_train)\n",
    "    test_init_op = ds_iter.make_initializer(ds_test)\n",
    "\n",
    "    # define placeholder for input vector X and target vector y\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    # initialize weights and bias  \n",
    "    weights = {'w1': tf.Variable(tf.truncated_normal([features, n_hidden_1], 0, 1, dtype=tf.float32)),\n",
    "           'w2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2], 0, 1, dtype=tf.float32)),\n",
    "          'out': tf.Variable(tf.truncated_normal([n_hidden_2, 1], 0, 1, dtype=tf.float32))}\n",
    "\n",
    "    biases = {'b1': tf.Variable(tf.truncated_normal([n_hidden_1], 0, 1, dtype=tf.float32)),\n",
    "          'b2': tf.Variable(tf.truncated_normal([n_hidden_2], 0, 1, dtype=tf.float32)),\n",
    "         'out': tf.Variable(tf.truncated_normal([1], 0, 1, dtype=tf.float32))}\n",
    "\n",
    "    # Create model\n",
    "    def multilayer_perceptron(x, weights, biases):\n",
    "        # Hidden layer 1 with ReLu activation\n",
    "        layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "        layer_1 = tf.nn.relu(layer_1)\n",
    "        layer_1 = tf.nn.dropout(layer_1, keep_prob) \n",
    "    \n",
    "        # Hidden layer 2 with ReLu activation\n",
    "        layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "        layer_2 = tf.nn.relu(layer_2)\n",
    "        layer_2 = tf.nn.dropout(layer_2, keep_prob) \n",
    "    \n",
    "        # Output layer with ReLu activation\n",
    "        out_layer = tf.add(tf.matmul(layer_2, weights['out']), biases['out'])\n",
    "        return out_layer\n",
    "              \n",
    "    # construct model\n",
    "    y_pred = multilayer_perceptron(next_x, weights, biases)\n",
    "    \n",
    "    # define cost function(mean squred error) and optimizer(gradient descent)\n",
    "    cost =  tf.losses.mean_squared_error(next_y, y_pred)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # initialize variables\n",
    "    init_op = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        for epoch in range(epochs):\n",
    "    \n",
    "            sess.run(train_init_op, feed_dict={X_placeholder: X_train, Y_placeholder: Y_train, batch_size_placeholder: batch_size})\n",
    "            count = 0\n",
    "\n",
    "            while True:\n",
    "                try:\n",
    "                    count += 1\n",
    "                    _, c = sess.run((optimizer, cost), feed_dict={keep_prob: 0.75})\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "#            print('Epoch:', (epoch + 1), 'cost =', c)\n",
    "        sess.run(test_init_op, feed_dict={X_placeholder: X_test, Y_placeholder: Y_test, batch_size_placeholder: len(X_test)})\n",
    "\n",
    "        results, test_cost = sess.run((y_pred, cost), feed_dict={keep_prob: 1.0})\n",
    "\n",
    "        print(test_cost)\n",
    "        print('R^2:', r_square(np.reshape(results, (len(results),)), Y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Transformation. Loop five times and retain R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- round 0-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevinyan/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22497645\n",
      "640 [25.07891769] 12.131691644654694 [180.94811567]\n",
      "R^2: [0.28651156]\n",
      "-------------------- round 1-----------------------\n",
      "0.20185351\n",
      "640 [39.15262427] 24.157151910140527 [181.11084318]\n",
      "R^2: [0.35037376]\n",
      "-------------------- round 2-----------------------\n",
      "0.25554347\n",
      "640 [5.0186372] 0.7731663693370132 [172.22505101]\n",
      "R^2: [0.18914825]\n",
      "-------------------- round 3-----------------------\n",
      "0.2529075\n",
      "640 [14.79956549] 5.552074959578189 [183.73842133]\n",
      "R^2: [0.21470523]\n",
      "-------------------- round 4-----------------------\n",
      "0.28470558\n",
      "640 [15.24529436] 29.83164321886855 [180.56847914]\n",
      "R^2: [0.04314719]\n",
      "-------------------- round 5-----------------------\n",
      "0.25675768\n",
      "640 [12.59107792] 6.591334931734666 [178.86789794]\n",
      "R^2: [0.13446834]\n",
      "-------------------- round 6-----------------------\n",
      "0.2270544\n",
      "640 [30.8785421] 16.161643125440047 [188.42999867]\n",
      "R^2: [0.31309636]\n",
      "-------------------- round 7-----------------------\n",
      "0.21082878\n",
      "640 [22.54865005] 11.085365778338074 [168.70629877]\n",
      "R^2: [0.27186905]\n",
      "-------------------- round 8-----------------------\n",
      "0.5341694\n",
      "640 [11.44251359] 177.33837711427702 [186.0004095]\n",
      "R^2: [0.00396941]\n",
      "-------------------- round 9-----------------------\n",
      "0.25062612\n",
      "640 [11.93577215] 3.2878878622987315 [180.59887495]\n",
      "R^2: [0.23992141]\n"
     ]
    }
   ],
   "source": [
    "for index_2 in range(10):\n",
    "    print(\"-------------------- round \"+str(index_2)+\"-----------------------\")    \n",
    "    x = np.where(train > 0, 1, 0)\n",
    "    seed = round(np.random.uniform(1, len(x)))\n",
    "    X_train, X_dev, Y_train, Y_dev = train_test_split(x, y, train_size = 0.80, random_state = seed)\n",
    "    X_val, X_test, Y_val, Y_test = train_test_split(X_dev, Y_dev, train_size = 0.50, random_state = seed)\n",
    "\n",
    "    X_placeholder = tf.placeholder(tf.float32, (None, X_train.shape[1]))\n",
    "    Y_placeholder = tf.placeholder(tf.float32, (None, Y_train.shape[1]))\n",
    "\n",
    "    # define parameters\n",
    "    features = np.shape(X_train)[1]\n",
    "    target_size = np.shape(X_train)[0]\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "\n",
    "    epochs = 900\n",
    "    batch_size = 300\n",
    "\n",
    "    batch_size_placeholder = tf.placeholder(tf.int64)\n",
    "    \n",
    "    # network parameters\n",
    "    n_hidden_1 = 50\n",
    "    n_hidden_2 = 25\n",
    "\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices(( X_placeholder, Y_placeholder )).shuffle(buffer_size=round(len(X_train) * 0.3)).batch(batch_size_placeholder)\n",
    "\n",
    "    ds_test = tf.data.Dataset.from_tensor_slices(( X_placeholder, Y_placeholder )).batch( batch_size_placeholder )\n",
    "    \n",
    "    ds_iter = tf.data.Iterator.from_structure(ds_train.output_types, ds_train.output_shapes)\n",
    "    \n",
    "    next_x, next_y = ds_iter.get_next()\n",
    "    \n",
    "    train_init_op = ds_iter.make_initializer(ds_train)\n",
    "    test_init_op = ds_iter.make_initializer(ds_test)\n",
    "    \n",
    "    # define placeholder for input vector X and target vector y\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # initialize weights and bias  \n",
    "    weights = {'w1': tf.Variable(tf.truncated_normal([features, n_hidden_1], 0, 1, dtype=tf.float32)),\n",
    "               'w2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2], 0, 1, dtype=tf.float32)),\n",
    "              'out': tf.Variable(tf.truncated_normal([n_hidden_2, 1], 0, 1, dtype=tf.float32))}\n",
    "\n",
    "    biases = {'b1': tf.Variable(tf.truncated_normal([n_hidden_1], 0, 1, dtype=tf.float32)),\n",
    "              'b2': tf.Variable(tf.truncated_normal([n_hidden_2], 0, 1, dtype=tf.float32)),\n",
    "             'out': tf.Variable(tf.truncated_normal([1], 0, 1, dtype=tf.float32))}\n",
    "\n",
    "    # Create model\n",
    "    def multilayer_perceptron(x, weights, biases):\n",
    "        # Hidden layer 1 with ReLu activation\n",
    "        layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "        layer_1 = tf.nn.relu(layer_1)\n",
    "        layer_1 = tf.nn.dropout(layer_1, keep_prob) \n",
    "    \n",
    "        # Hidden layer 2 with ReLu activation\n",
    "        layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "        layer_2 = tf.nn.relu(layer_2)\n",
    "        layer_2 = tf.nn.dropout(layer_2, keep_prob) \n",
    "    \n",
    "        # Output layer with ReLu activation\n",
    "        out_layer = tf.add(tf.matmul(layer_2, weights['out']), biases['out'])\n",
    "        return out_layer\n",
    "              \n",
    "    # construct model\n",
    "    y_pred = multilayer_perceptron(next_x, weights, biases)\n",
    "    \n",
    "    # define cost function(mean squred error) and optimizer(gradient descent)\n",
    "    cost =  tf.losses.mean_squared_error(next_y, y_pred)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # initialize variables\n",
    "    init_op = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        for epoch in range(epochs):\n",
    "    \n",
    "            sess.run(train_init_op, feed_dict={X_placeholder: X_train, Y_placeholder: Y_train, batch_size_placeholder: batch_size})\n",
    "            count = 0\n",
    "\n",
    "            while True:\n",
    "                try:\n",
    "                    count += 1\n",
    "                    _, c = sess.run((optimizer, cost), feed_dict={keep_prob: 0.75})\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "#            print('Epoch:', (epoch + 1), 'cost =', c)\n",
    "        sess.run(test_init_op, feed_dict={X_placeholder: X_test, Y_placeholder: Y_test, batch_size_placeholder: len(X_test)})\n",
    "\n",
    "        results, test_cost = sess.run((y_pred, cost), feed_dict={keep_prob: 1.0})\n",
    "\n",
    "        print(test_cost)\n",
    "        print('R^2:', r_square(np.reshape(results, (len(results),)), Y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model that we propose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Transformation. Loop five times and retain R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- round 0-----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevinyan/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23457174\n",
      "640 [13.3190856] 5.48568518861196 [169.27432592]\n",
      "R^2: [0.19104112]\n",
      "-------------------- round 1-----------------------\n",
      "0.18930474\n",
      "640 [44.87569262] 23.36120350507565 [178.55619552]\n",
      "R^2: [0.48278325]\n",
      "-------------------- round 2-----------------------\n",
      "0.19495007\n",
      "640 [38.72409361] 20.187079587941753 [181.09791951]\n",
      "R^2: [0.41018103]\n",
      "-------------------- round 3-----------------------\n",
      "0.17077231\n",
      "640 [44.90389045] 27.797440629818034 [166.06855764]\n",
      "R^2: [0.43679304]\n",
      "-------------------- round 4-----------------------\n",
      "0.20687433\n",
      "640 [27.6337272] 14.691699228164302 [172.58509562]\n",
      "R^2: [0.30116439]\n",
      "-------------------- round 5-----------------------\n",
      "0.1577361\n",
      "640 [53.52184868] 35.20855031744672 [170.86965912]\n",
      "R^2: [0.47615584]\n",
      "-------------------- round 6-----------------------\n",
      "0.15188622\n",
      "640 [64.18155803] 42.80655472546791 [182.15933504]\n",
      "R^2: [0.52827347]\n",
      "-------------------- round 7-----------------------\n",
      "0.14907596\n",
      "640 [69.97442868] 52.569411761526 [173.98515689]\n",
      "R^2: [0.53534457]\n",
      "-------------------- round 8-----------------------\n",
      "0.16207042\n",
      "640 [58.00671243] 42.14768486650251 [171.75668296]\n",
      "R^2: [0.46480323]\n",
      "-------------------- round 9-----------------------\n",
      "0.14819357\n",
      "640 [66.32070234] 58.03233014748912 [169.0661374]\n",
      "R^2: [0.44830295]\n"
     ]
    }
   ],
   "source": [
    "for index_3 in range(10):\n",
    "    print(\"-------------------- round \"+str(index_3)+\"-----------------------\")    \n",
    "\n",
    "    train = train.apply(lambda x: np.log(x+1))\n",
    "    x = train.values\n",
    "    seed = round(np.random.uniform(1, len(x)))\n",
    "    X_train, X_dev, Y_train, Y_dev = train_test_split(x, y, train_size = 0.80, random_state = seed)\n",
    "    X_val, X_test, Y_val, Y_test = train_test_split(X_dev, Y_dev, train_size = 0.50, random_state = seed)\n",
    "\n",
    "    X_placeholder = tf.placeholder(tf.float32, (None, X_train.shape[1]))\n",
    "    Y_placeholder = tf.placeholder(tf.float32, (None, Y_train.shape[1]))\n",
    "\n",
    "    # define parameters\n",
    "    features = np.shape(X_train)[1]\n",
    "    target_size = np.shape(X_train)[0]\n",
    "\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    epochs = 900\n",
    "    batch_size = 300\n",
    "\n",
    "    batch_size_placeholder = tf.placeholder(tf.int64)\n",
    "\n",
    "    # network parameters\n",
    "    n_hidden_1 = 50\n",
    "    n_hidden_2 = 25\n",
    "\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices(( X_placeholder, Y_placeholder )).shuffle(buffer_size=round(len(X_train) * 0.3)).batch(batch_size_placeholder)\n",
    "\n",
    "    ds_test = tf.data.Dataset.from_tensor_slices(( X_placeholder, Y_placeholder )).batch( batch_size_placeholder )\n",
    "\n",
    "    ds_iter = tf.data.Iterator.from_structure(ds_train.output_types, ds_train.output_shapes)\n",
    "\n",
    "    next_x, next_y = ds_iter.get_next()\n",
    "\n",
    "    train_init_op = ds_iter.make_initializer(ds_train)\n",
    "    test_init_op = ds_iter.make_initializer(ds_test)\n",
    "\n",
    "    # define placeholder for input vector X and target vector y\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    # initialize weights and bias  \n",
    "    weights = {'w1': tf.Variable(tf.truncated_normal([features, n_hidden_1], 0, 1, dtype=tf.float32)),\n",
    "           'w2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2], 0, 1, dtype=tf.float32)),\n",
    "          'out': tf.Variable(tf.truncated_normal([n_hidden_2, 1], 0, 1, dtype=tf.float32))}\n",
    "\n",
    "    biases = {'b1': tf.Variable(tf.truncated_normal([n_hidden_1], 0, 1, dtype=tf.float32)),\n",
    "          'b2': tf.Variable(tf.truncated_normal([n_hidden_2], 0, 1, dtype=tf.float32)),\n",
    "         'out': tf.Variable(tf.truncated_normal([1], 0, 1, dtype=tf.float32))}\n",
    "\n",
    "    # Create model\n",
    "    def multilayer_perceptron(x, weights, biases):\n",
    "        # Hidden layer 1 with ReLu activation\n",
    "        layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "        layer_1 = tf.nn.relu(layer_1)\n",
    "        layer_1 = tf.nn.dropout(layer_1, keep_prob) \n",
    "    \n",
    "        # Hidden layer 2 with ReLu activation\n",
    "        layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "        layer_2 = tf.nn.relu(layer_2)\n",
    "        layer_2 = tf.nn.dropout(layer_2, keep_prob) \n",
    "        \n",
    "        # Output layer with ReLu activation\n",
    "        out_layer = tf.add(tf.matmul(layer_2, weights['out']), biases['out'])\n",
    "        return out_layer\n",
    "              \n",
    "    # construct model\n",
    "    y_pred = multilayer_perceptron(next_x, weights, biases)\n",
    "\n",
    "    # define cost function(mean squred error) and optimizer(gradient descent)\n",
    "    cost =  tf.losses.mean_squared_error(next_y, y_pred)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # initialize variables\n",
    "    init_op = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        for epoch in range(epochs):\n",
    "    \n",
    "            sess.run(train_init_op, feed_dict={X_placeholder: X_train, Y_placeholder: Y_train, batch_size_placeholder: batch_size})\n",
    "            count = 0\n",
    "\n",
    "            while True:\n",
    "                try:\n",
    "                    count += 1\n",
    "                    _, c = sess.run((optimizer, cost), feed_dict={keep_prob: 0.75})\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "#            print('Epoch:', (epoch + 1), 'cost =', c)\n",
    "        sess.run(test_init_op, feed_dict={X_placeholder: X_test, Y_placeholder: Y_test, batch_size_placeholder: len(X_test)})\n",
    "\n",
    "        results, test_cost = sess.run((y_pred, cost), feed_dict={keep_prob: 1.0})\n",
    "\n",
    "        print(test_cost)\n",
    "        print('R^2:', r_square(np.reshape(results, (len(results),)), Y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "notrans=[0.01047271, 0.00809794, 0.00475776, 0.11151784, 0.06138477, 0.12013887, 0.06175471, 0.00549668, 0.0037739, 0.13213858]\n",
    "bintrans=[0.28651156,0.35037376,0.18914825, 0.21470523,0.04314719,0.13446834,0.31309636,0.27186905,0.00396941,0.23992141]\n",
    "logtrans=[0.19104112, 0.48278325, 0.41018103, 0.43679304, 0.30116439, 0.47615584, 0.52827347, 0.53534457, 0.46480323,0.44830295]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a306ae828>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(trials, notrans, c='g')\n",
    "plt.scatter(trials, bintrans, c = 'r')\n",
    "plt.scatter(trials, logtrans, c = 'b')\n",
    "plt.xlabel('trial number')\n",
    "plt.ylabel('R^2')\n",
    "plt.legend(('no transformation', 'binary transformation', 'logarithmic transformation'), bbox_to_anchor=(1.53, 1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
