{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('ACT11_competition_training.csv', dtype={\"MOLECULE\": object, \"Act\": float})\n",
    "y=train['Act'].values\n",
    "y=np.reshape(y,(-1,1))\n",
    "train=train.drop(['Act', 'MOLECULE'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Provided by MERCK\n",
    "def r_square(X, Y):\n",
    "    \"\"\" r^2 value defined by the competition host, r^2 = 1 indicates 100% prediction accuracy\n",
    "    \"\"\"\n",
    "    avx = np.mean(X)\n",
    "    avy = np.mean(Y)\n",
    "    sum1, sumx, sumy = 0, 0, 0\n",
    "    for i in range(len(X)):\n",
    "        sum1 += (X[i] - avx)*(Y[i] - avy)\n",
    "        sumx += (X[i] - avx)*(X[i] - avx)\n",
    "        sumy += (Y[i] - avy)*(Y[i] - avy)\n",
    "    print(len(X), sum1, sumx, sumy)\n",
    "    return sum1*sum1/(sumx*sumy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_3 in range(10):\n",
    "    print(\"-------------------- round \"+str(index_3)+\"-----------------------\")    \n",
    "\n",
    "    train = train.apply(lambda x: np.log(x+1))\n",
    "    x = train.values\n",
    "    seed = round(np.random.uniform(1, len(x)))\n",
    "    X_train, X_dev, Y_train, Y_dev = train_test_split(x, y, train_size = 0.80, random_state = seed)\n",
    "    X_val, X_test, Y_val, Y_test = train_test_split(X_dev, Y_dev, train_size = 0.50, random_state = seed)\n",
    "\n",
    "    X_placeholder = tf.placeholder(tf.float32, (None, X_train.shape[1]))\n",
    "    Y_placeholder = tf.placeholder(tf.float32, (None, Y_train.shape[1]))\n",
    "\n",
    "    # define parameters\n",
    "    features = np.shape(X_train)[1]\n",
    "    target_size = np.shape(X_train)[0]\n",
    "\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    epochs = 900\n",
    "    batch_size = 300\n",
    "\n",
    "    batch_size_placeholder = tf.placeholder(tf.int64)\n",
    "\n",
    "    # network parameters\n",
    "    n_hidden_1 = 50\n",
    "    n_hidden_2 = 25\n",
    "\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices(( X_placeholder, Y_placeholder )).shuffle(buffer_size=round(len(X_train) * 0.3)).batch(batch_size_placeholder)\n",
    "\n",
    "    ds_test = tf.data.Dataset.from_tensor_slices(( X_placeholder, Y_placeholder )).batch( batch_size_placeholder )\n",
    "\n",
    "    ds_iter = tf.data.Iterator.from_structure(ds_train.output_types, ds_train.output_shapes)\n",
    "\n",
    "    next_x, next_y = ds_iter.get_next()\n",
    "\n",
    "    train_init_op = ds_iter.make_initializer(ds_train)\n",
    "    test_init_op = ds_iter.make_initializer(ds_test)\n",
    "\n",
    "    # define placeholder for input vector X and target vector y\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    # initialize weights and bias  \n",
    "    weights = {'w1': tf.Variable(tf.truncated_normal([features, n_hidden_1], 0, 1, dtype=tf.float32)),\n",
    "           'w2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2], 0, 1, dtype=tf.float32)),\n",
    "          'out': tf.Variable(tf.truncated_normal([n_hidden_2, 1], 0, 1, dtype=tf.float32))}\n",
    "\n",
    "    biases = {'b1': tf.Variable(tf.truncated_normal([n_hidden_1], 0, 1, dtype=tf.float32)),\n",
    "          'b2': tf.Variable(tf.truncated_normal([n_hidden_2], 0, 1, dtype=tf.float32)),\n",
    "         'out': tf.Variable(tf.truncated_normal([1], 0, 1, dtype=tf.float32))}\n",
    "\n",
    "    # Create model\n",
    "    def multilayer_perceptron(x, weights, biases):\n",
    "        # Hidden layer 1 with ReLu activation\n",
    "        layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "        layer_1 = tf.nn.relu(layer_1)\n",
    "        layer_1 = tf.nn.dropout(layer_1, keep_prob) \n",
    "    \n",
    "        # Hidden layer 2 with ReLu activation\n",
    "        layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "        layer_2 = tf.nn.relu(layer_2)\n",
    "        layer_2 = tf.nn.dropout(layer_2, keep_prob) \n",
    "        \n",
    "        # Output layer with ReLu activation\n",
    "        out_layer = tf.add(tf.matmul(layer_2, weights['out']), biases['out'])\n",
    "        return out_layer\n",
    "              \n",
    "    # construct model\n",
    "    y_pred = multilayer_perceptron(next_x, weights, biases)\n",
    "\n",
    "    # define cost function(mean squred error) and optimizer(gradient descent)\n",
    "    cost =  tf.losses.mean_squared_error(next_y, y_pred)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # initialize variables\n",
    "    init_op = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        for epoch in range(epochs):\n",
    "    \n",
    "            sess.run(train_init_op, feed_dict={X_placeholder: X_train, Y_placeholder: Y_train, batch_size_placeholder: batch_size})\n",
    "            count = 0\n",
    "\n",
    "            while True:\n",
    "                try:\n",
    "                    count += 1\n",
    "                    _, c = sess.run((optimizer, cost), feed_dict={keep_prob: 0.75})\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "#            print('Epoch:', (epoch + 1), 'cost =', c)\n",
    "        sess.run(test_init_op, feed_dict={X_placeholder: X_test, Y_placeholder: Y_test, batch_size_placeholder: len(X_test)})\n",
    "\n",
    "        results, test_cost = sess.run((y_pred, cost), feed_dict={keep_prob: 1.0})\n",
    "\n",
    "        print(test_cost)\n",
    "        print('R^2:', r_square(np.reshape(results, (len(results),)), Y_test))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
